# General

**Andres Hernandez (2016), Model Calibration with Neural Networks**
**Andres Hernandez (2017) Model Calibration: Global Optimizer vs. Neural Network**

+ Paper: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2812140
+ https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2996930
+ slides: https://www.quantlib.org/slides/qlum17/hernandez.pdf
+ Hull white, bermudan swaptions, compared vs Quantlib
+ Code: https://github.com/Andres-Hernandez/CalibrationNN

**Interpretability in deep learning for finance (2021)**

+ https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3829947
+ 10000 datapoints, parameter space from Horvath et al. (2019) and Roeder and Dimitrof, sampled uniformly in ever ydimension
+ Uniform grid of strikes and maturities
+ FCNN the data is scaled in a range from 0 to 1 before being inputted to the network, while
for the CNN the data is scaled to have a mean of 0 and a variance of 1
+ Local and global interpretability

**Andrey Itkin, Deep learning calibration of option pricing models: some pitfalls and solutions (2019)**
+ https://arxiv.org/pdf/1906.03507.pdf
+ Use random sampling over a grid of parameters in the Black-Scholes case, and partition datasets into train and test (over the same grid of parameters)
+ Trained on true BS prices
+ 0.03 RMSE (on normalised call prices), 0.1% MAPE after only 15 epochs

**Medhi Thomas, Pricing and calibration of stochastic models via neural networks**
+ https://www.imperial.ac.uk/media/imperial-college/faculty-of-natural-sciences/department-of-mathematics/math-finance/TOMAS_MEHDI_01390785.pdf
+ Medhi Thomas MSc Thesis


**Liu, Shuaiqiang, Anastasia Borovykh, Lech Grzelak, and Cornelis Oosterlee. 2019a. A neural network-based framework for financial model calibration**
  
**Liu, Shuaiqiang, Cornelis Oosterlee, and Sander Bohte. 2019b. Pricing options and computing implied volatilities using neural networks** 

+ https://arxiv.org/pdf/1901.08943.pdf
+ Black-Scholes, Heston settings
+ Uses train-test split, k-fold cross validation for hyperparameter tuning
+ Optimal architecture from 3-fold cross validation: 200 epochs, glorot uniform, adam, 1024 batch size no dropout, no batch-norm, relu activation , 4 hidden layers with 400 hidden units
+ A maximum of 24300 samples
+ Direct training on true prices
+ Use a larger parameter space as test set (similar to Anatonov-Piterbarg paper) to evaluate extrapolation
+ 1 million data points for heston, latin hypercube sampling, targest generated by latin hypercube sampling 
+ No evaluation of greek errors
+  Batch normalisation, dropout
+ Hyperparameter tuning by k-fold cross validation
+ MSE
+ Train on true model prices for a range of parameters


# Local Stochastic Volatility


**Katia Babbar, William McGhee, A DEEP LEARNING APPROACH TO EXOTIC OPTION PRICING UNDER LSVOL**

+ https://www.bayes.city.ac.uk/__data/assets/pdf_file/0007/494080/DeepLearningExoticOptionPricingLSVOL_KB_CassBusinessSchool_2019.pdf



# Rough Volatility

**Deep Learning (Rough) Volatility**

+ Video: https://www.youtube.com/watch?v=O03erV5nYXA
+ https://arxiv.org/abs/1901.09647
+ Article by bocconi students https://bsic.it/rough-volatility/


**Christian Bayer, Benjamin Stemper, Deep calibration of rough stochastic volatility models (2018)**

+ Rough (Bergomi) models presents itself as opportunity, given the lack of analtyical approximations in many cases, necessitating MC
+ https://github.com/roughstochvol
+ https://github.com/bstemper/deep_rough_calibration  
+ Cut up one dataset into train, val, test
+ Sample more from dense parameter regions (can be obtained from historical data)
+ Relu activation
+ Feature scaling,  weight initialisation, regularisation, batch norm
+ Bayesian approach to parameters

**Dirk Roeder, Georgi Dimitroff, Volatility model calibration with neural networks a comparison between direct and indirect methods (2020)**

+ https://github.com/roederd/volatility_model_calibration_with_nn


# HJM

**Accuracy of Deep Learning in Calibrating HJM Forward Curves (2021)**

+ SPDEs
+ Calibration to full HJM is very difficult
+ Pointwise vs Grid
+ Code: https://github.com/silvialava/HJM_calibration_with_NN
+ Energy markets
+ **FRED ESPEN BENTH, NILS DETERING, LUCA GALIMBERTI, NEURAL NETWORKS IN FReCHET SPACES**
+ https://arxiv.org/abs/2109.13512
+ Related Work: **FRED ESPEN BENTH, NILS DETERING, LUCA GALIMBERTI, PRICING OPTIONS ON FLOW FORWARDS BY NEURAL NETWORKS IN HILBERT SPACE**

+ Related Work: **Deep Learning in a Generalized HJM-type Framework Through Arbitrage-Free Regularization**
+ Nelson Siegel

